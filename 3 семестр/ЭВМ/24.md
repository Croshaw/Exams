[[ЭВМ|<==]]
# Параллельные архитектуры вычислительных систем
Параллельным называется такое выполнение программы, когда две или более части одной и той же программы выполняются одновременно двумя или более центральными процессорами одного и того же или разных компьютеров. В первом случае архитектура вычислительной системы считается многопроцессорной (мультипроцессорной), а во втором — многомашинной (мультикомпьютерной). Вычислительные системы, содержащие более одного центрального процессора, называются параллельными.
# Законы Амдала
**Первый закон Амдала**. Производительность вычислительной системы, состоящей из нескольких связанных между собой устройств, определяется самым непроизводительным устройством.
**Второй закон Амдала**. Пусть вычислительная система состоит из $р$ процессоров. Предположим, что $k$ из $N$ операций алгоритма могут выполняться только последовательно. Пусть $\beta = k/N$ — доля последовательных операций в алгоритме, $0 \leq \beta \leq 1$. Тогда максимально возможное ускорение системы
$R = \frac{1}{(\beta + \frac{1 - \beta}{p})}$
# Топология параллельных систем
**Процессорным элементом** считается любой процессор в составе параллельной вычислительной системы.
Способ соединения процессорных элементов и модулей памяти в параллельной вычислительной системе называется **топологией системы**.
Существуют **статические** и **динамические** топологии. В статических топологиях соединение элементов системы фиксировано и не изменяется с течением времени. В динамических схемах все компоненты системы подключаются к переключательному устройству — **коммутатору**, которое может соединять любые компоненты друг с другом. В целом статические топологии отличаются, с одной стороны, более высоким быстродействием, так как все связи между процессорными элементами известны и уже установлены, а с другой — невысокими возможностями масштабирования системы, так как включение нового элемента обычно требует физической перестройки системы связей и перенастройки программного обеспечения. Динамические топологии, наоборот, отличаются высокими возможностями масштабируемости и меньшим быстродействием.
Существует много различных способов построения коммутаторов, используемых для организации связей внутри параллельных систем. На рис. 1 изображены два варианта их построения. В **матричном** коммутаторе (рис. 1, а) каждый процессорный элемент имеет линии связи, которые связывают его с каждым из модулей памяти (МП). В узлах пересечения линий связи находятся простые переключающие устройства, обеспечивающие соединение или разрыв связи. В общем случае такой коммутатор может содержать n х m входов, к которым могут подключаться процессорные элементы, модули памяти или другие коммутаторы в любых нужных комбинациях. Достоинствами такого устройства коммутатора являются его высокое быстродействие, возможность одновременной связи любых процессорных элементов между собой и с любыми модулями памяти, высокая надежность. Но матричные коммутаторы имеют существенный недостаток — количество необходимого оборудования растёт как $n^2$ при увеличении количества входов $n$.

![[Pasted image 20240109231311.png]]
Рисунок 1 — Упрощённые схемы коммутаторов: а — матричного; б — каскадного

Для удешевления коммутаторов используются различные **каскадные схемы**. На рис. 1, б показана схема коммутатора, построенного на базе простых матричных коммутаторов (МК 2 х 2), имеющих 2 х 2 входа. Каждый из простых коммутаторов связан с входом другого простого коммутатора, а также с двумя процессорными элементами или модулями памяти. Так обеспечивается связь между любыми двумя подключенными к коммутатору устройствами, аналогичная связь в матричных коммутаторах. При этом общее количество переключательных элементов в такой схеме возрастает только как $(n*log_2n)/2$, что для больших $n$ гораздо меньше, чем $n^2$. Однако наличие промежуточных коммутаторов вызывает замедление работы устройства в целом.
Топология, в которой каждый узел имеет связь с любым другим (рис. 2, а), называется **полносвязной**. Такая топология отличается наиболее высокой производительностью, но имеет ограниченные возможности масштабирования и высокую стоимость. Если система содержит $n$ узлов, то каждый узел должен иметь $n - 1$ связей, а общее количество связей в полносвязной топологии равно $n*(n-1)/2$. В большинстве случаев разработчики не имеют материальных ресурсов для построения таких систем.

![[Pasted image 20240109231717.png]]
Рисунок 2 — Базовые топологии параллельных вычислительных систем

Если в топологии отсутствует связь между какими-либо двумя узлами системы, то такая топология считается **неполносвязной**.
На рис. 2, б изображена **топология с общей шиной**, которая является аналогом архитектуры с общей шиной однопроцессорных компьютеров. Топология отличается простотой и дешевизной. Вместе с тем ей присуща низкая надежность, так как отказ любого узла приводит к выходу из строя всей системы. Кроме того, в топологии с общей шиной включение каждого нового узла приводит к уменьшению общей пропускной способности шины, что свидетельствует о плохой масштабируемости такой топологии.
На рис. 2, в представлена топология типа **кольцо**, являющаяся развитием топологии с общей шиной. Фактически кольцо представляет собой общую шину с соединенными концами, поэтому оно обладает теми же достоинствами и недостатками, что и общая шина. К преимуществам относится более высокая скорость обмена, так как передача данных может осуществляться в двух направлениях и можно выбрать более короткий путь, чем в случае использования общей шины.
Еще одна базовая топология — **типа звезда** — изображена на рис. 2, г. В системе выделяется один центральный узел, который имеет отдельную связь со всеми остальными узлами. Любой другой узел имеет связь только с центральным. Такая топология отличается в целом более высокой надежностью по сравнению с общей шиной или кольцом, но в ней предъявляются более высокие требования к производительности и надежности центрального узла, который становится критическим для системы.